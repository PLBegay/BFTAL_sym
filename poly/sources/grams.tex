\chapter{Grammaires formelles et hiérarchie de Chomsky}
\label{grammaires}


\section{Principe général}

Une \textbf{grammaire formelle} est une série de \textbf{règles} permettant de générer des mots. Ces règles utilisent des \textbf{symboles} dits \textbf{terminaux} (les lettres "normales", par convention en minuscules), et d'autres dits \textbf{non-terminaux} (normalement dénotés par des lettres majuscules). Un de ces symboles non-terminaux, appelé \textbf{axiome}, indique le début de toute génération de mot. On présente d'abord le fonctionnement des grammaires et les concepts de base à l'aide de quelques exemples. 

\begin{example}
On présente la grammaire dénotée par ces deux règles :

\[
\begin{cases}
S \rightarrow \epsilon \\
S \rightarrow abS 
\end{cases}
\]

Cette grammaire contient un seul symbole non-terminal, S. Il s'agit donc automatiquement de l'axiome. Le symbole S peut se transformer en $\epsilon$ (première règle) ou en $abS$ (deuxième règle). Cette grammaire génère l'ensemble des mots composés uniquement de symboles terminaux ($a$ et $b$) qu'on peut obtenir en partant de l'axiome S et en appliquant autant de fois qu'on veut les règles données. Dans ce qui suit, on écrira $\rightarrow_1$ pour une application de la première règle et $\rightarrow_2$ pour la seconde.

On peut par exemple obtenir le mot $ab$ de la façon suivante :

\[
S \rightarrow_2 abS \rightarrow_1 ab
\]

Dans cette suite de transformation, appelée \textbf{dérivation}, on remplace d'abord l'axiome par $abS$ à l'aide de la deuxième règle. Puisque $abS$ contient le facteur $S$, on peut utiliser \textit{localement} la deuxième règle pour faire disparaître ce S. Dans ce cas, ce qu'il y avait autour du S, le \textbf{contexte}, reste inchangé.

On peut également obtenir le mot $abab$ :

\[
S \rightarrow_2 \textcolor{blue}{ab}S \rightarrow_2 \textcolor{blue}{ab}\textcolor{red}{ab}S \rightarrow_1 \textcolor{blue}{ab}\textcolor{red}{ab}
\]

ou ababab :


\[
S \rightarrow_2 \textcolor{blue}{ab}S \rightarrow_2 \textcolor{blue}{ab}\textcolor{red}{ab}S \rightarrow_2 \textcolor{blue}{ab}\textcolor{red}{ab}\textcolor{green}{ab}S \rightarrow_1  \textcolor{blue}{ab}\textcolor{red}{ab}\textcolor{green}{ab}
\]

Il n'est pas obligatoire d'utiliser toutes les règles d'une grammaire. On peut donc générer le mot vide :

\[
S \rightarrow_1 \epsilon
\]

On se rend compte assez vite que la grammaire \textbf{engendre} le langage $(ab)^*$.

\end{example}


\begin{example}
\label{LRgram}
Un symbole non-terminal peut générer d'autres symboles non-terminaux, et même plusieurs en même temps. De plus, un non-terminal peut générer un autre mot que juste $\epsilon$. Ces deux points sont illustrés par la grammaire suivante :

\[
\begin{cases}
S \rightarrow LaaR \\
L \rightarrow Lb \\
L \rightarrow ab \\
R \rightarrow bR \\
R \rightarrow ba
\end{cases}
\]

Quelques exemples de dérivations dans cette grammaire :

\[
 S \rightarrow_1 LaaR \rightarrow_2 LbaaR \rightarrow_2 LbbaaR \rightarrow_4 LbbaabR \rightarrow_3 abbbaabR \rightarrow_5 abbbaabba
\]

\[
 S \rightarrow_1 LaaR \rightarrow_3 abaaR \rightarrow_5 abaaba
 \]
 
 On note $\rightarrow_i^j$ $j$ utilisations de la règle numéro $i$, comme dans la dérivation suivante :
 
 \[
 S \rightarrow_1 LaaR \rightarrow_2^5 LbbbbbaaR \rightarrow_3 abbbbbbaaR \rightarrow_4^3 abbbbbbaabbbR \rightarrow_5 abbbbbbaabbbba
 \]

\end{example}

\begin{exercice}
Quel est le langage engendré par la grammaire de l'exemple \ref{LRgram} ?
\end{exercice}

\begin{exercice}
\label{grammab}
Quel est le langage reconnu par la grammaire suivante ?

\[
\begin{cases}
S \rightarrow A \\
S \rightarrow B \\
A \rightarrow aA \\
A \rightarrow \epsilon \\
B \rightarrow bB \\
B \rightarrow \epsilon
\end{cases}
\]

\end{exercice}

\begin{exercice}
\label{grammsigma}
Quel est le langage reconnu par la grammaire suivante ?

\[
\begin{cases}
S \rightarrow aS \\
S \rightarrow bS \\
S \rightarrow \epsilon 
\end{cases}
\]

\end{exercice}

\begin{exercice}
Donner l'ensemble des mots qui admettent deux dérivations (ie. peuvent être construits de plusieurs façons différentes) dans la grammaire de l'exercice \ref{grammab}. Même question pour celle de l'exercice \ref{grammsigma}.
\end{exercice}

\begin{example}
\label{ggramabcn}
On a jusqu'ici seulement vu des exemples de grammaires avec un seul non-terminal à gauche des flèches de réécriture. Il est cependant possible de préciser le contexte dans lequel les réécritures doivent se faire, comme dans la grammaire suivante :

\[
\begin{cases}
S \rightarrow SABC \\
S \rightarrow \epsilon \\
AB \rightarrow BA \\
BA \rightarrow AB \\
AC \rightarrow CA \\
CA \rightarrow AC \\
BC \rightarrow CB \\
CB \rightarrow BC \\
A \rightarrow a \\
B \rightarrow b \\
C \rightarrow c
\end{cases}
\]

Toute dérivation dans cette grammaire fonctionne de la façon suivante : on commence par utiliser la première règle $n$ fois pour produire $S(ABC)^n$. Ensuite, on utilise la deuxième règle pour faire disparaître S et se retrouver avec $(ABC)^n$. Les règles 3 à 8 permettent ensuite de mélanger les symboles non-terminaux comme on l'entend. Une fois qu'ils ont été disposés de la façon voulue, on les transforme en $a$, $b$ et $c$ avec les règles 9, 10 et 11.

Le langage engendré par cette grammaire est donc celui des mots contenant autant de $a$ que de $b$ et de $c$.
\end{example}

\paragraph{Remarque} Dans l'exemple ci-dessus, on découpe toute dérivation en 4 étapes : utilisation de la première règle, puis de la seconde, puis des 3 à 8, et enfin des 9 à 11. Cette présentation nous semble améliorer la compréhension de l'exemple et du langage engendré, mais techniquement, rien n'empêche de mélanger les étapes, comme dans la dérivation suivante :

 \[
 S \rightarrow_1 SABC \rightarrow_9 SaBC \rightarrow_7 SaCB \rightarrow_{11} SaCb \rightarrow_1 SABCaCb \rightarrow_2 ABCaCB \rightarrow_{9,10,11}^5 abcacb 
 \]

 Où $\rightarrow_{9,10,11}^5$ indique 5 utilisations de règles parmi 9, 10 et 11.
 
 \section{Formalisation}
 
 Maintenant qu'on a un peu joué avec les grammaires formelles, on peut regarder comment elles se formalisent. Techniquement donc, une grammaire formelle est un quadruplet $\big \langle\Sigma, V, S, R \big \rangle$, où
 
 \begin{itemize}
 \item $\Sigma$ est l'ensemble des \textbf{symboles terminaux}
 \item $V$ est l'ensemble des \textbf{symboles non-terminaux}
 \item $S \in V$ est l'\textbf{axiome}
 \item $R$ est l'ensemble des \textbf{règles de production}, ou règles de réécriture. Ces dernières forment un sous-ensemble de $(\Sigma \cup V)^*V(\Sigma \cup V)^* \times (\Sigma \cup V)^*$, cad. qu'elles doivent toujours avoir au moins un non-terminal à gauche. 
 \end{itemize}
 
 
 
\begin{example}
La grammaire de l'exemple \ref{LRgram} s'écrit 

\[
\big \langle \{a,b\},\{S,L,R\},S, \begin{cases}
S \rightarrow LaaR \\
L \rightarrow Lb \\
L \rightarrow ab \\
R \rightarrow bR \\
R \rightarrow ba
\end{cases}
 \big \rangle
\]


\begin{definition}{Réécriture / dérivation immédiate}{}
Soient $p$, $s$ et $g$ des mots sur l'alphabet $(\Sigma \cup V)$, et $f \in (\Sigma \cup V)^*V(\Sigma \cup V)^*$. Si la règle $r$ est de la forme $f \rightarrow g$, alors le mot $pfs$ se \textbf{réécrit} (ou dérive) \textbf{immédiatement} en $pgs$ via la règle $r$, ce qu'on note 

\[
pfs \rightarrow_r pgs
\]

Plus généralement, étant donnée une grammaire $G$, on dit qu'elle réécrit (ou dérive) immédiatement un mot $u$ en $v$ ssi. il existe une règle $r$ dans la grammaire telle que $u$ se réécrit immédiatement en $v$ via la règle $r$. On écrit ceci 

\[
pfs \rightarrow_G pgs
\]
\end{definition}

\paragraph{Remarque} $u \rightarrow_r v$ est parfois noté $u \xrightarrow{r} v$. De plus, quand il n'y a pas d'ambiguïté sur la grammaire étudiée, on note $u \rightarrow v$ plutôt que $u \rightarrow_G v$.


\end{example}


\begin{definition}{Réécriture / dérivation}{}
Soient une grammaire $G$ et deux mots $u$ et $v$. On dit que $u$ se \textbf{réécrit} (ou dérive) en $v$ avec $G$ ssi. il existe une série (potentiellement nulle) de réécritures immédiates menant de $u$ à $v$ dans $G$. On le note 

\[
u \rightarrow_G^* v
\]

ou $u \rightarrow^* v$ s'il n'y a pas d'ambiguïté sur la grammaire étudiée.

\end{definition}
 
\begin{example}
Dans l'exemple \ref{ggramabcn}, on a 

\[
S \rightarrow^* SABCaCb \rightarrow^* abcacb
\]

et donc 

\[
S \rightarrow^* abcacb
\]
\end{example}
 
%\begin{definition}{Proto-mot}{}
%Un \textbf{proto-mot} est un mot contenant 
%\end{definition}
% proto-mot, dérivations équivalentes, gauche
% defs utiles dans la suite ?

\begin{definition}{Langage engendré}{}
Le langage engendré par le mot $f$ dans une grammaire $G$, noté $L_G(f)$, est l'ensemble des mots de $\Sigma^*$ (formés uniquement de symboles terminaux) en lesquelles on peut réécrire l'axiome de $f$ en suivant les règles de $G$. Plus formellement,

\[
L_G(f) = \{u \in \Sigma^* ~|~f \rightarrow_G^* u\}
\]

Le langage engendré par une grammaire est le langage engendré par l'axiome dans cette grammaire. Soit une grammaire $G$ d'axiome $S$, son langage engendré, noté $L_G$, est $L_G(S)$.
\end{definition}

\begin{example}
Soit $G$ la grammaire de l'exemple \ref{ggramabcn}. 

\[
L_G = \{w \in \Sigma^* ~|~|w|_a = |w|_b = |w|_c \}
\]
\end{example}